<h1 align="center" style="border-bottom: none">
    <b>
        <a href="https://www.google.com"> AUTOMATED IMAGE CAPTIONING </a><br>
    </b>
    ⭐️ ⭐️ <br>
</h1>

# [`Demo video link `](https://youtu.be/KXnNQInuM2I) 
## Team Details
`Team number` : VH156

| Name    | Email           |
|---------|-----------------|
| J.AJAY SAI | 9921004293@klu.ac.in |
| G.HARINATH CHOWDARY | 9921004205@klu.ac.in |
| K.REVANTH | 99210041050@klu.ac.in |
|D.HRUDAY VIKAS|99210041178@klu.ac.in|

<div style="display: flex; flex-wrap: wrap;">
    <img src="https://daniel.lasiman.com/assets/by-post/image-captioning/karpathy-examples.jpg" alt="Image 1" style="width: 30%; margin: 5px;">
    <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQNi07tVgpsUuBytjg5BM36TsoTgF_H_5NRIBb3o9S8cA&s" alt="Image 2" style="width: 30%; margin: 5px;">
    <img src="https://www.researchgate.net/publication/347760884/figure/fig5/AS:1002138310287361@1615939800757/Examples-of-poor-image-captioning-generated-by-state-of-the-art-systems-These-captions.png" alt="Image 3" style="width: 30%; margin: 5px;">
</div>

## Problem statement 
Create an automatic image captioning program that can automatically create captions for hundreds of images, making it easier for people with visual impairments to access content and improving search and indexing for multimedia databases. the need for solution to this problem statement arises from several factors like accessebility,content indexing and searching,assistive technology etc.., Content creators and researches,data scientists etcc face this problem
## About the project
These solutions use deep learning models, such as CNNs for image segmentation and RNNs for recurrent neural networks, as well as transformer-based models such as Transformer and BERT for caption generation based on image segmentation.
Image feature extraction (CNN) is the process of extracting high-level information from an input image. CNNs capture information about the objects, shapes and textures in the image, which are used as inputs for the captioning system.RNN (or transformer-based) is the process by which an RNN decodes the image features.Descriptive Text Generation (RNN) is a process by which a sequence of descriptive text is generated in a sequence.The next word in a caption is predicted by the RNN based on the previous generated words.This process incorporates visual information from image features as well as linguistic context. 

## Technical implemntaion 
mention the approach and how you have solved the problem with the technology , utilize multiple flowcharts to explain your solutions and approach
->LOAD IMAGE
->PREPROCESS IMAGE
->EXTRACT IMAGE FEATURES
->GENERATE CAPTION
->OUTPUT CAPTION


## Techstacks used 
`nodejs` , `react` , `ml` , `Pyton` , `tech stack 1`

## How to run locally 
explain detailed steps to run your project locally , example to run a react application 
- step 1 : clone the repo 
- step 2 : you can find different files in the repo
- step 3 : we have the code file in that,select it and run the code
- step 4 : then we need to do ctrl+click on the automated image captioner
- step 5 : u will be directed to the chrome and upload the image 
- step 6 :then we get the output

# What's next ?
multimodal fusion: Combine multiple modalities (text, audio, other contextual information) with the visual content to create captions that are richer and more contextually relevant.fusion-based model: Explore fusion-based modeling, attention mechanisms and graph-based representation to integrate different sources of data.
fine-grained understanding: Improve the system’s ability to capture finer-grained information and relationships within an image by leveraging techniques (fine-grained Object Recognition, spatial reasoning and scene understanding) that could allow for richer captions with deeper semantic understanding.
Addressing Ethical Concerns
Addressing Ethical Issues with Automated Image Captioning
Addressing Bias in dataset annotations
Addressing Misuse of Generated Captions
Addressing Privacy Concerns with Sensitive Image Content Developing Guidance, Frameworks, or Regulatory Measures to Ensure Responsible Deployment and Use of Captioning Systems Extend multilingual captioning capabilities with the ability to generate captions in multiple languages. Cross-Language Transfer Learning, Multilingual Embeddings, or Language-agnostic Representations can help caption in languages where training data is limited.
## Declaration
We confirm that the project showcased here was either developed entirely during the hackathon or underwent significant updates within the hackathon timeframe. We understand that if any plagiarism from online sources is detected, our project will be disqualified, and our participation in the hackathon will be revoked.
